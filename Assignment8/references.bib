
@book{pebesma_spatial_2022,
	title = {Spatial {Data} {Science} with applications in {R}},
	url = {https://keen-swartz-3146c4.netlify.app/pointpatterns.html#coordinate-reference-systems-1},
	abstract = {description\_xx},
	urldate = {2022-06-24},
	author = {Pebesma, Edzer and Bivand, Roger},
	year = {2022},
	file = {Snapshot:/Users/edgar/Zotero/storage/JTFDVRAX/pointpatterns.html:text/html},
}

@misc{baddeley_spatstat_2021,
	title = {Spatstat: {Spatial} {Point} {Pattern} {Analysis}, {Model}- {Fitting}, {Simulation}, {Tests}.},
	url = {http://spatstat.org/},
	urldate = {2022-06-24},
	author = {Baddeley, Adrian and Turner, Rolf and Rubak, Ege},
	year = {2021},
	file = {spatstat - spatstat website:/Users/edgar/Zotero/storage/T6XQMW7U/spatstat.org.html:text/html},
}

@article{diggle_kernel_1985,
	title = {A {Kernel} {Method} for {Smoothing} {Point} {Process} {Data}},
	volume = {34},
	issn = {0035-9254},
	url = {https://www.jstor.org/stable/2347366},
	doi = {10.2307/2347366},
	abstract = {A method for estimating the local intensity of a one-dimensional point process is described. The estimator uses an adaptation of Rosenblatt's kernel method of non-parametric probability density estimation, with a correction for end-effects. An expression for the mean squared error is derived on the assumption that the underlying process is a stationary Cox process, and this result is used to suggest a practical method for choosing the value of the smoothing constant. The performance of the estimator is illustrated using simulated data. An application to data on the locations of joints along a coal seam is described. The extension to two-dimensional point processes is noted.},
	number = {2},
	urldate = {2022-06-24},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Diggle, Peter},
	year = {1985},
	note = {Publisher: [Wiley, Royal Statistical Society]},
	pages = {138--147},
}

@misc{baddeley_r_nodate,
	title = {R: {Nearest} {Neighbour} {Distance} {Function} {G}},
	url = {http://127.0.0.1:20567/library/spatstat.core/html/Gest.html},
	urldate = {2022-06-24},
	author = {Baddeley, Adrian and Turner, Rolf},
	file = {R\: Nearest Neighbour Distance Function G:/Users/edgar/Zotero/storage/9XTURAVK/Gest.html:text/html},
}

@misc{baddeley_r_nodate-1,
	title = {R: {K}-function},
	url = {http://127.0.0.1:20567/library/spatstat.core/html/Kest.html},
	urldate = {2022-06-24},
	author = {Baddeley, Adrian and Turner, Rolf},
	file = {R\: K-function:/Users/edgar/Zotero/storage/7DKJP5X7/Kest.html:text/html},
}

@article{ripley_modelling_1977,
	title = {Modelling {Spatial} {Patterns}},
	volume = {39},
	issn = {2517-6161},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1977.tb01615.x},
	doi = {10.1111/j.2517-6161.1977.tb01615.x},
	abstract = {Spatial point processes may be analysed at two levels. Quadrat and distance methods were designed for the sampling of a population in the field. In this paper we consider those situations in which a map of a spatial pattern has been produced at some cost and we wish to extract the maximum possible information. We review the stochastic models which have been proposed for spatial point patterns and discuss methods by which the fit of such a model can be tested. Certain models are shown to be the equilibrium distributions of spatialâ€“temporal stochastic processes. The theory is illustrated by several case studies.},
	language = {en},
	number = {2},
	urldate = {2022-06-24},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Ripley, B. D.},
	year = {1977},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1977.tb01615.x},
	keywords = {cell shapes, hard-core model, markov point process, mathematical morphology, point process, spatial pattern},
	pages = {172--192},
	file = {Full Text PDF:/Users/edgar/Zotero/storage/VXU5S87E/Ripley - 1977 - Modelling Spatial Patterns.pdf:application/pdf;Snapshot:/Users/edgar/Zotero/storage/RMEFFT2C/j.2517-6161.1977.tb01615.html:text/html},
}

@misc{veronesi_introductory_2015,
	title = {Introductory {Point} {Pattern} {Analysis} of {Open} {Crime} {Data} in {London} {\textbar} {R}-bloggers},
	url = {https://www.r-bloggers.com/2015/05/introductory-point-pattern-analysis-of-open-crime-data-in-london/},
	abstract = {IntroductionPolice in Britain (http://data.police.uk/) not only register every single crime they encounter, and include coordinates, but also distribute their data free on the web.They have two ways of distributing data: the first is through an API, which is extremely easy to use but returns only a limited number of crimes for each request, the second is a good old manual download from this page http://data.police.uk/data/. Again this page is extremely easy to use, they did a very good job in securing that people can access and work with these data; we can just select the time range and the police force from a certain area, and then wait for the system to create the dataset for us. I downloaded data from all forces for May and June 2014 and it took less than 5 minutes to prepare them for download.These data are distributed under the Open Government Licence, which allows me to do basically whatever I want with them (even commercially) as long as I cite the origin and the license.Data PreparationFor completing this experiment we would need the following packages: sp, raster, spatstat, maptools and plotrix.As I mentioned above, I downloaded all the crime data from the months of May and June 2014 for the whole Britain. Then I decided to focus on the Greater London region, since here the most crimes are committed and therefore the analysis should be more interesting (while I am writing this part I have not yet finished the whole thing so I may be wrong). Since the Open Government License allows me to distribute the data, I uploaded them to my website so that you can easily replicate this experiment.The dataset provided by the British Police is in csv format, so to load it we just need to use the read.csv function:data str(data)'data.frame': 79832 obs. of 12 variables: \$ Crime.ID : Factor w/ 55285 levels "","0000782cea7b25267bfc4d22969498040d991059de4ebc40385be66e3ecc3c73",..: 1 1 1 1 1 2926 28741 19664 45219 21769 ... \$ Month : Factor w/ 1 level "2014-05": 1 1 1 1 1 1 1 1 1 1 ... \$ Reported.by : Factor w/ 1 level "Metropolitan Police Service": 1 1 1 1 1 1 1 1 1 1 ... \$ Falls.within : Factor w/ 1 level "Metropolitan Police Service": 1 1 1 1 1 1 1 1 1 1 ... \$ Longitude : num 0.141 0.137 0.14 0.136 0.135 ... \$ Latitude : num 51.6 51.6 51.6 51.6 51.6 ... \$ Location : Factor w/ 20462 levels "No Location",..: 15099 14596 1503 1919 12357 1503 8855 14060 8855 8855 ... \$ LSOA.code : Factor w/ 4864 levels "","E01000002",..: 24 24 24 24 24 24 24 24 24 24 ... \$ LSOA.name : Factor w/ 4864 levels "","Barking and Dagenham 001A",..: 2 2 2 2 2 2 2 2 2 2 ... \$ Crime.type : Factor w/ 14 levels "Anti-social behaviour",..: 1 1 1 1 1 3 3 5 7 7 ... \$ Last.outcome.category: Factor w/ 23 levels "","Awaiting court outcome",..: 1 1 1 1 1 21 8 21 8 8 ... \$ Context : logi NA NA NA NA NA NA ...This dataset provides a series of useful information regarding the crime: its locations (longitude and latitude in degrees), the address (if available), the type of crime and the court outcome (if available). For the purpose of this experiment we would only need to look at the coordinates and the type of crime.For some incidents the coordinates are not provided, therefore before we can proceed we need to remove NAs from data:data},
	language = {en-US},
	urldate = {2022-06-25},
	author = {Veronesi, Fabio},
	month = may,
	year = {2015},
	file = {Snapshot:/Users/edgar/Zotero/storage/IPJLWNUJ/introductory-point-pattern-analysis-of-open-crime-data-in-london.html:text/html},
}
